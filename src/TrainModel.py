import torch
from Utils.vocabulary import Vocabulary
from Utils.config import external_fun_vocabulary
from model.EmbedderGraphModel import EmbedderGraphModel
from Utils.preprocessedDataset import PreprocessedDataset,create_batch_data
from torch_geometric.loader import DataLoader

if __name__ == '__main__': 
    max_vocab_size = 10000
    vocab = Vocabulary(freq_file=external_fun_vocabulary, max_vocab_size=max_vocab_size)

    model = EmbedderGraphModel(external_vocab=vocab)

    root_path: str = 'C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/pyG_prova/'
    i_batch_size = 3
    local_device = torch.device("cpu")
    
    train_dataset = PreprocessedDataset(root_dataset=root_path, train_or_test='train')
    loader = DataLoader(dataset=train_dataset, batch_size=i_batch_size, shuffle=True)  # default of prefetch_factor = 2 # num_workers=4
    
    for index, data in enumerate(loader):
        if index >= 3:
            break
        _real_batch, _position, _hash, _external_list, _function_edges, _true_classes = create_batch_data(one_batch=data)
        print(data)
        print("Real Batch: ", _real_batch)
        print("Hash: ", _hash)
        print("Position: ", _position)
        print("external_list: ", _external_list)
        print("function_edge: ", _function_edges)
        print("true_classes: ", _true_classes)
        print("\n")


    _real_batch = _real_batch.to(local_device)
    _position = torch.tensor(_position, dtype=torch.long).cpu()
    _true_classes = _true_classes.float().cpu()

     
    train_batch_final = model(local_method_batch=_real_batch, local_bt_positions=_position, bt_external_names=_external_list, bt_all_method_edges=_function_edges, local_device=local_device)
    train_batch_final = train_batch_final.squeeze()

    print(train_batch_final)