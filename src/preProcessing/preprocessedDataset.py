import os
import torch
from datetime import datetime
from torch_geometric.loader import DataLoader
from torch_geometric.data import Dataset
from Utils.functions_helper import create_batch_data
    

class PreprocessedDataset(Dataset):
    def __init__(self, root_dataset, train_or_test, transform=None, pre_transform=None):
        super(PreprocessedDataset, self).__init__(None, transform, pre_transform)
        self.flag = train_or_test.lower()
        self.rootDS = root_dataset
        self.rootDS_files = os.listdir(root_dataset)
    
    @staticmethod
    def _list_files_for_pt(the_path):
        files = []
        for name in os.listdir(the_path):
            if os.path.splitext(name)[-1] == '.pt':
                files.append(name)
        return files
    
    def len(self):
        return len(self.rootDS_files)
    
    def get(self, idx):
        idx_data = torch.load(os.path.join(self.rootDS, "{}.pt".format(idx+1)).replace("\\","/"))
        return idx_data


def _simulating(_dataset, _batch_size: int):
    print("\nBatch size = {}".format(_batch_size))
    time_start = datetime.now()
    print("start time: " + time_start.strftime("%Y-%m-%d@%H:%M:%S"))
    
    # https://github.com/pytorch/fairseq/issues/1560
    # https://github.com/pytorch/pytorch/issues/973#issuecomment-459398189
    # loaders_1 = DataLoader(dataset=benign_exe_dataset, batch_size=10, shuffle=True, num_workers=0)
    # increasing the shared memory: ulimit -SHn 51200
    loader = DataLoader(dataset=_dataset, batch_size=_batch_size, shuffle=True)  # default of prefetch_factor = 2 # num_workers=4
    
    for index, data in enumerate(loader):
        if index >= 3:
            break
        _real_batch, _position, _hash, _external_list, _function_edges, _true_classes = create_batch_data(one_batch=data)
        print(data)
        print("Real Batch: ", _real_batch)
        print("Hash: ", _hash)
        print("Position: ", _position)
        print("external_list: ", _external_list)
        print("function_edge: ", _function_edges)
        print("true_classes: ", _true_classes)
        print("\n")
    
    time_end = datetime.now()
    print("end time: " + time_end.strftime("%Y-%m-%d@%H:%M:%S"))
    print("All time = {}\n\n".format(time_end - time_start))


if __name__ == '__main__':
    root_path: str = 'C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/pyG_prova/'
    i_batch_size = 3
    
    train_dataset = PreprocessedDataset(root_dataset=root_path, train_or_test='train')
    print(train_dataset.rootDS_files)
    print(len(train_dataset.rootDS_files), len(train_dataset))
    _simulating(_dataset=train_dataset, _batch_size=i_batch_size)
    
    # valid_dataset = MalwareDetectionDataset(root=root_path, train_or_test='valid')
    # print(valid_dataset.malware_root, valid_dataset.benign_root)
    # print(len(valid_dataset.malware_files), len(valid_dataset.benign_files), len(valid_dataset))
    # _simulating(_dataset=valid_dataset, _batch_size=i_batch_size)
    
    # test_dataset = MalwareDetectionDataset(root=root_path, train_or_test='test')
    # print(test_dataset.malware_root, test_dataset.benign_root)
    # print(len(test_dataset.malware_files), len(test_dataset.benign_files), len(test_dataset))
    # _simulating(_dataset=test_dataset, _batch_size=i_batch_size)