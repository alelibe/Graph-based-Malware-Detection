import torch
from torch import nn
from torch_geometric.data import Batch, Data
from preProcessing.vocabulary import Vocabulary
from torch.nn import functional as pt_f
from torch_geometric.nn.glob import global_max_pool, global_mean_pool

class EmbedderGraphModel(nn.Module):
    def __init__(self) -> None:
        super(EmbedderGraphModel,self).__init__()



    def forward_cfg_gnn(self, local_batch: Batch):
        in_x, edge_index = local_batch.x, local_batch.edge_index
        for i in range(self.cfg_filter_length - 1):
            out_x = getattr(self, 'CFG_gnn_{}'.format(i + 1))(x=in_x, edge_index=edge_index)
            out_x = pt_f.relu(out_x, inplace=True)
            out_x = self.dropout(out_x)
            in_x = out_x
        local_batch.x = in_x
        return local_batch
    
    def aggregate_cfg_batch_pooling(self, local_batch: Batch):
        if self.pool == 'global_max_pool':
            x_pool = global_max_pool(x=local_batch.x, batch=local_batch.batch)
        elif self.pool == 'global_mean_pool':
            x_pool = global_mean_pool(x=local_batch.x, batch=local_batch.batch)
        else:
            raise NotImplementedError
        return x_pool
    
    def forward_fcg_gnn(self, function_batch: Batch):
        in_x, edge_index = function_batch.x, function_batch.edge_index
        for i in range(self.fcg_filter_length - 1):
            out_x = getattr(self, 'FCG_gnn_{}'.format(i + 1))(x=in_x, edge_index=edge_index)
            out_x = pt_f.relu(out_x, inplace=True)
            out_x = self.dropout(out_x)
            in_x = out_x
        function_batch.x = in_x
        return function_batch
    
    def aggregate_fcg_batch_pooling(self, function_batch: Batch):
        if self.pool == 'global_max_pool':
            x_pool = global_max_pool(x=function_batch.x, batch=function_batch.batch)
        elif self.pool == 'global_mean_pool':
            x_pool = global_mean_pool(x=function_batch.x, batch=function_batch.batch)
        else:
            raise NotImplementedError
        return x_pool
    
    def aggregate_final_skip_pooling(self, x, batch):
        if self.pool == 'global_max_pool':
            x_pool = global_max_pool(x=x, batch=batch)
        elif self.pool == 'global_mean_pool':
            x_pool = global_mean_pool(x=x, batch=batch)
        else:
            raise NotImplementedError
        return x_pool
    

    def forward(self,local_method_batch: Batch, local_bt_positions: list, bt_external_names: list, bt_all_method_edges,local_device: torch.device):
        acfg_local_batch = self.forward_cfg_gnn(local_batch=local_method_batch)
        x_cfg_pool = self.aggregate_cfg_batch_pooling(local_batch=acfg_local_batch)

        fcg_list = []
        fcg_internal_list = []
        for idx_batch in range(len(local_bt_positions) - 1):
            start_acfg_pos, end_acfg_pos = local_bt_positions[idx_batch: idx_batch + 2]
            
            idx_x_cfg = x_cfg_pool[start_acfg_pos: end_acfg_pos]
            fcg_internal_list.append(idx_x_cfg)
            
            idx_x_external = self.external_embedding_layer(torch.tensor([bt_external_names[idx_batch]], dtype=torch.long).to(local_device))
            idx_x_external = idx_x_external.squeeze(dim=0)
            
            idx_x_total = torch.cat([idx_x_cfg, idx_x_external], dim=0)
            idx_function_edge = torch.tensor(bt_all_method_edges[idx_batch], dtype=torch.long)
            idx_graph_data = Data(x=idx_x_total, edge_index=idx_function_edge).to(local_device)
            
            fcg_list.append(idx_graph_data)

        fcg_batch = Batch.from_data_list(fcg_list)

        rtn_fcg_batch = self.forward_fcg_gnn(function_batch=fcg_batch)  # [batch_size, max_node_size, dim]
        x_fcg_pool = self.aggregate_fcg_batch_pooling(function_batch=rtn_fcg_batch)  # [batch_size, 1, dim] => [batch_size, dim]
        batch_final = x_fcg_pool

