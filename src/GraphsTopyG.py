# This code trasform each graph (stored in a json file) in a pyg object
from Utils.config import preprocessedGraphs,external_fun_vocabulary,pyg_objects,preprocess_path,tesseract
from Utils.vocabulary import Vocabulary
from Utils.trasformGraphs import graph_list_2_pyg_object
import pandas as pd
import shutil
import os
import sys
from sklearn.model_selection import train_test_split


def split_dataset():
    csv_path = preprocess_path +"dataset.csv"
    df = pd.read_csv(csv_path)
    # df.drop(columns=df.columns[0], axis=1, inplace=True)
    df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)
    df_train, df_valid = train_test_split(df_train, test_size=0.20, random_state=42)
    df_train.to_csv(preprocess_path+"train_set.csv",index=False)
    df_valid.to_csv(preprocess_path+"valid_set.csv",index=False)
    df_test.to_csv(preprocess_path+"test_set.csv",index=False)


    if not os.path.exists(preprocess_path+"TrainingSet"):
        os.mkdir(preprocess_path+"TrainingSet")
    if not os.path.exists(preprocess_path+"ValidSet"):
        os.mkdir(preprocess_path+"ValidSet")
    if not os.path.exists(preprocess_path+"TestSet"):
        os.mkdir(preprocess_path+"TestSet")

    # moveTrainFile = lambda x: shutil.move(pyg_objects+str(x)+".pt",preprocess_path+"TrainingSet/"+str(x)+".pt")
    copyTrainFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",preprocess_path+"TrainingSet/"+str(x)+".pt")
    df_train["index_file"].apply(copyTrainFile)

    # moveValidFile = lambda x: shutil.move(pyg_objects+str(x)+".pt",preprocess_path+"ValidSet/"+str(x)+".pt")
    copyValidFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",preprocess_path+"ValidSet/"+str(x)+".pt")
    df_valid["index_file"].apply(copyValidFile)
    
    # moveTestFile = lambda x: shutil.move(pyg_objects+str(x)+".pt",preprocess_path+"TestSet/"+str(x)+".pt")
    copyTestFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",preprocess_path+"TestSet/"+str(x)+".pt")
    df_test["index_file"].apply(copyTestFile)


def split_with_tess():
    csv_path = preprocess_path +"dataset.csv"
    df = pd.read_csv(csv_path)

    if not os.path.exists(tesseract+"trainingSet_tess"):
        os.mkdir(tesseract+"trainingSet_tess")
    if not os.path.exists(tesseract+"testSet_tess"):
        os.mkdir(tesseract+"testSet_tess")

    # TESSERACT FRAMEWORK: constraint 1
    df_train = df[df["timestamp"] <= "2015"]
    df_train.to_csv(tesseract+"train_set.csv",index=False)
    df_test = df[df["timestamp"] > "2015"] 
    df_test.to_csv(tesseract+"test_set.csv",index=False)

    # TESSERACT FRAMEWORK: constraint 2
    # count of goodware and malware for each <'timestamp','label'>
    df_count_train = df_train.groupby(['timestamp','label']).count()
    # for each unique timestamp in the resulting count
    for ts in df_count_train['timestamp'].unique():
        # if the len of the dataframe (i.e. the number of class) is 1 it means that
        # it has only goodware or only malware violating cons 2 
        if len(df_count_train[df_count_train['timestamp']==ts]) == 1:
            # drop the timestamp rows with only goodware or only malware
            df_train = df_train[df_train['timestamp'] != ts]

    # count of goodware and malware for each <'timestamp','label'>
    df_count_test = df_test.groupby(['timestamp','label']).count()
    # for each unique timestamp in the resulting count
    for ts in df_count_test['timestamp'].unique():
        # if the len of the dataframe (i.e. the number of class) is 1 it means that
        # it has only goodware or only malware violating cons 2 
        if len(df_count_test[df_count_test['timestamp']==ts]) == 1:
            # drop the timestamp rows with only goodware or only malware
            df_test = df_test[df_test['timestamp'] != ts]
    
    # TODO: constraint 3

    copyTrainFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",tesseract+"trainingSet_tess/"+str(x)+".pt")
    df_train["index_file"].apply(copyTrainFile)

    copyTestFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",tesseract+"testSet_tess/"+str(x)+".pt")
    df_test["index_file"].apply(copyTestFile)


        

if __name__ == '__main__':
    # transfrom graphs of each apk to one graph
    # graphAggregator()

    max_vocab_size = 10000
    vocabulary = Vocabulary(freq_file=external_fun_vocabulary, max_vocab_size=max_vocab_size)

    #convert json graph in pyG object
    # graph_list_2_pyg_object(dir_graphs=preprocessedGraphs,label=1,vocab=vocabulary)

    if str(sys.argv[1]) == "--tess":
        split_with_tess()
    else:
        split_dataset()