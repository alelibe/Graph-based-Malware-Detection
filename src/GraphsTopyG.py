# This code trasform each graph (stored in a json file) in a pyg object
from Utils.config import preprocessedGraphs,external_fun_vocabulary,pyg_objects,preprocess_path
from Utils.vocabulary import Vocabulary
from Utils.trasformGraphs import graph_list_2_pyg_object
import pandas as pd
import shutil
import os
from sklearn.model_selection import train_test_split


def split_dataset():
    csv_path = preprocess_path +"dataset.csv"
    df = pd.read_csv(csv_path)
    # df.drop(columns=df.columns[0], axis=1, inplace=True)
    df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)
    df_train,df_valid = train_test_split(df_train, test_size=0.20, random_state=42)
    df_train.to_csv(preprocess_path+"train_set.csv",index=False)
    df_valid.to_csv(preprocess_path+"valid_set.csv",index=False)
    df_test.to_csv(preprocess_path+"test_set.csv",index=False)


    if not os.path.exists(preprocess_path+"TrainingSet"):
        os.mkdir(preprocess_path+"TrainingSet")
    if not os.path.exists(preprocess_path+"ValidSet"):
        os.mkdir(preprocess_path+"ValidSet")
    if not os.path.exists(preprocess_path+"TestSet"):
        os.mkdir(preprocess_path+"TestSet")

    # moveTrainFile = lambda x: shutil.move(pyg_objects+str(x)+".pt",preprocess_path+"TrainingSet/"+str(x)+".pt")
    copyTrainFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",preprocess_path+"trainingSet/"+str(x)+".pt")
    df_train["index_file"].apply(copyTrainFile)

    # moveValidFile = lambda x: shutil.move(pyg_objects+str(x)+".pt",preprocess_path+"ValidSet/"+str(x)+".pt")
    copyValidFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",preprocess_path+"validSet/"+str(x)+".pt")
    df_valid["index_file"].apply(copyValidFile)
    
    # moveTestFile = lambda x: shutil.move(pyg_objects+str(x)+".pt",preprocess_path+"TestSet/"+str(x)+".pt")
    copyTestFile = lambda x: shutil.copy(pyg_objects+str(x)+".pt",preprocess_path+"testSet/"+str(x)+".pt")
    df_test["index_file"].apply(copyTestFile)
    
        

if __name__ == '__main__':
    # transfrom graphs of each apk to one graph
    # graphAggregator()

    max_vocab_size = 10000
    vocabulary = Vocabulary(freq_file=external_fun_vocabulary, max_vocab_size=max_vocab_size)

    #convert json graph in pyG object
    graph_list_2_pyg_object(dir_graphs=preprocessedGraphs,label=1,vocab=vocabulary)

    split_dataset()