# This code trasform each graph (stored in a json file) in a pyg object
import json
import torch
import os
from torch_geometric.data import Data
from tqdm import tqdm
from Utils.config import preprocessedGraphs,external_fun_vocabulary,pyg_objects
from vocabulary import Vocab


def graph_list_2_pyg_object(dir_graphs: str, label: int, vocab: Vocab):
    index = 0
    for jsonl_file in tqdm(os.listdir(dir_graphs)):
        graph = os.path.join(dir_graphs,jsonl_file).replace("\\","/")
        
        with open(graph, "r", encoding="utf-8") as file:
            graphAPK = json.load(file)

            graph_hash = graphAPK['hash']
            
            acfg_list = []
            for one_acfg in graphAPK['acfg_list']:  # list of dict of acfg
                block_features = one_acfg['block_features']
                block_edges = one_acfg['block_edges']
                one_acfg_data = Data(x=torch.tensor(block_features, dtype=torch.float), edge_index=torch.tensor(block_edges, dtype=torch.long))
                acfg_list.append(one_acfg_data)
            
            graph_function_names = graphAPK['function_names']
            graph_function_edges = graphAPK['function_edges']
            
            local_function_name_list = graph_function_names[:len(acfg_list)]
            assert len(acfg_list) == len(local_function_name_list), "The length of ACFG_List should be equal to the length of Local_Function_List"
            external_function_name_list = graph_function_names[len(acfg_list):]
            
            external_function_index_list = [vocab[f_name] for f_name in external_function_name_list]
            index += 1
            torch.save(Data(hash=graph_hash, local_acfgs=acfg_list, external_list=external_function_index_list, function_edges=graph_function_edges, targets=label), pyg_objects+"{}.pt".format(index))
            # print(index)


if __name__ == '__main__':
    max_vocab_size = 10000
    vocabulary = Vocab(freq_file=external_fun_vocabulary, max_vocab_size=max_vocab_size)
    graph_list_2_pyg_object(dir_graphs=preprocessedGraphs, label=1, vocab=vocabulary)