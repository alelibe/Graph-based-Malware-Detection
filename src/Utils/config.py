# Data
graphs = "C:/Users/Alessia/Desktop/Unimi/Tesi/DataPreparation/Graphs"
preprocessedGraphs = "C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/preProcessedGraphs/"
preprocess_path = "C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/"
pyg_objects = "C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/pyG_objects/"
standard_train = "C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/Std_Train/" # this folder contains the split dataset without considering Tesseract constraints
tesseract = "C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/Tesseract/" # this folder contains the split dataset considering Tesseract constraints
external_fun_vocabulary = "C:/Users/Alessia/Desktop/Unimi/Tesi/Preprocess/train_external_function_name_vocab.jsonl"
actualDS_meta = "C:/Users/Alessia/Documents/GitHub/Graph-based-Malware-Detection/DREBIN/actualDS_from_DREBIN/actualDS-meta.json"
actualDS_y = "C:/Users/Alessia/Documents/GitHub/Graph-based-Malware-Detection/DREBIN/actualDS_from_DREBIN/actualDS-y.json"
training_history = "C:/Users/Alessia/Documents/GitHub/Graph-based-Malware-Detection/src/model/history/"


#train parameters
max_epochs = 15
train_batch_size = 128
valid_batch_size = 128
test_batch_size = 128

#optimezer parameters
lr = 1e-3
wd = 1e-5

#model parameters
max_vocab_size = 10000


